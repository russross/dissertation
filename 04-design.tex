\chapter{The Envoy File System}\label{cha:design}

This chapter outlines the design of Envoy, a file system to support flexible commodity computing in service clusters. This chapter focuses on the architecture and general features, along with the main algorithms and administrative considerations. Details about protocols and implementation decisions are reserved for the next chapter, which discusses the prototype implementation.

The chapter starts with a discussion of the environment, including the expectations placed on the hardware and tools outside the scope of this dissertation. It then discusses the architecture of the entire system and how individual operations are supported by it. A discussion of how private and shared images are presented to and managed by clients is followed by discussion of how they are managed internally to optimise the overall system. The chapter concludes with a discussion of failure and recovery concerns.

\section{Assumptions}

Envoy is designed for service clusters, with the needs of flexibly commodity computation informing its assumptions about security and client demands.

Service clusters are assumed to have well-provisioned networks. High-speed local-area networking makes communication between nodes in the cluster cheap and fast, and switched interconnects make communication between pairs of nodes possible without significantly affecting the rest of the cluster. Redundant connections reduce the impact of failures, so network partitions---while still possible---are expected to be rare.

Nodes are also assumed to fail independently. Clusters are expected to run in machine rooms with redundant power sources and ample cooling. While commodity hardware is prone to failure, well-managed hardware can still be reliable and well-engineered clusters can isolate failing nodes, preventing groups of machines from failing together.

Service clusters run jobs for untrusted clients, but the environment itself is assumed to be trustworthy. Virtual machine managers isolate clients and prevent many malicious forms of behaviour. In particular, the network is assumed to be secure, with address spoofing and packet sniffing by clients prevented by the virtual machine managers and related systems. In addition, Envoy's own services can run in a secure environment, isolated from untrusted clients.

This work also assumes that other aspects of service-cluster management are provided by suitable solutions. Procedures for billing, managing client sessions, balancing load, allocating resources, etc., are omitted from this dissertation. It is further assumed that Envoy can cooperate with management software when necessary, though specific details are ignored. Envoy provides mechanisms to support client file system image management, but it does not prescribe procedures or management practices, as these must necessarily depend on other aspects of the system in addition to the storage system.

\section{Architecture}

Services access Envoy using a client-server file system interface. Each physical machine in the service cluster runs an administrative virtual machine that manages the storage processes for all services on that machine. These processes partition the local disk between a contribution to the shared storage pool and a local persistent cache as well as provide a standard interface allowing clients on the machine to access the file system. \figref{fig:single-machine} illustrates a typical machine. Client access to the system is restricted to a simple, well-understood client-server protocol, and a trusted server process acts as a proxy to the complete system \cite{shapiro}. Byzantine failure from clients is less of a problem, because they have a limited interface to the system and hold no trusted data.

\begin{figure}[t]
\centering
\includegraphics[width=\figwidth]{figures/single-machine}
\caption[Layout of Envoy services in a single machine]{Each physical machine has a single administrative VM that hosts the Envoy services. This VM exports a network file system protocol to other service VMs running on the same machine.}
\label{fig:single-machine}
\end{figure}

The file system management processes join a cluster-wide service that is comprised of two primary layers, as illustrated in \figref{fig:layers}. Storage is managed by the lower level, which allows a small set of basic file operations on objects. The storage interface is stateless and the storage service makes no attempt to prevent or manage concurrent requests or to enforce any kind of security policy. Objects are extents of bytes with a small set of attributes.

On top of the storage service is the envoy layer, which builds a hierarchical file system out of objects, coordinates access to files, provides authentication and access control services, manages caching, and exports a standard network file system interface for services to access.

\begin{figure}[t]
\centering
\includegraphics[width=\figwidth]{figures/layers}
\caption[The layers of the Envoy file system]{The envoy service coordinates access to provide a single, coherent view of the distributed file system. It relies on the storage service, which provides a repository of objects referenced by unique identifiers.}
\label{fig:layers}
\end{figure}

In the remainder of this section I detail the functionality and requirements of these systems and consider the tradeoffs of various design decisions.

\subsection{Distribution}

\figref{fig:client-server} depicts a commonly-used storage arrangement using a series of dedicated file servers to handle the needs of many clients. This architecture is successfully used in many settings, and, despite alternatives developed over the years, is still the dominant storage model in practical use.

\begin{figure}[t]
\centering
\includegraphics[width=\figwidth]{figures/client-server}
\caption[Machines served by a series of client-server file systems]{A popular storage solution for groups of clients involves a series of dedicated servers. Content on the servers is carefully managed to distribute storage demand and transaction load between the servers.}
\label{fig:client-server}
\end{figure}

The client-server model has obvious flaws when applied to clusters with many transient clients. Data placement decisions must balance space requirements and expected access rates in order to avoid overloading a particular server. Rebalancing---a disruptive and time consuming job---may be necessary in response to added clients, added servers, added disks, variations in client workload, and accumulation of data over time.

With the service cluster model, the problem is made even worse. To make efficient use of increasingly powerful hardware, each physical machine may host many services, each of which requires a boot image as well as access to the data relevant to its intended task. Dividing each machine means that there may be an order of magnitude more virtual machines than physical machines, putting excessive demands on a centralised storage infrastructure \cite{hospodor}. Single-purpose services may also be short lived and demand may vary by time of day, making manual balancing impractical.

The client-server model has not endured as long as it has simply for lack of alternatives, however. It has many strengths that can inform the design of a more distributed architecture. With a single server managing shared data, concurrent access can be managed simply through explicit leases and cache invalidation, centralised caching with synchronous access, or through a lock manager. Whatever the mechanism for resolving conflicts, a centralised server is ideally suited to detecting and responding to concurrent requests because it is the point on the access graph at which all requests converge. The consistency of data that has reached the server is as good as its backing store.

The simplicity of a server is also a virtue. A failstop model for reliability can generally be assumed, backups are relatively straightforward, the server is typically dedicated to a single task or is shared with other trusted services, and the semantics are simple to define in terms of client behaviour%
\footnote{NFS versions 2 and 3 have notoriously complicated consistency semantics, but this is almost entirely due to client policies. NFS server semantics are straightforward.}.

The chief faults of a centralised system are the introduction of a single point of failure and the inability to scale beyond the network and disk bandwidth that can be hosted by a single server. While these limits are unacceptable at large scales, they are quite serviceable for small groups of clients.

For clients that are sharing data, it is difficult to improve on a centralised server. For sufficiently overlapping data sets, any consistent model will degrade to something resembling a server during periods of contention because all interested clients will have to synchronise their access to the contended bits. A single arbitrator will ultimately oversee each bit of data, whether it is a traditional server, a lease-holding client, or a quorum of cooperating peers.

Sharing cache space is also a benefit of consolidated control of shared data. As the performance gap between disk access and memory access continues to grow, efficient use of available cache space becomes increasingly important. Once again, a single centralised cache fails the scalability requirement, but a shared cache for a smaller set of clients with overlapping data needs provides attractive properties. Accessing a cache across a high-speed network can be faster than accessing a local disk \cite{dahlin94b}, so in a cluster setting, organising data to maximise the aggregate cache is more valuable than organising it to localise access \cite{franklin}. Stated another way, the effective cache size of the combined cluster is greater when redundant entries are consolidated, and maximising the combined cache size to avoid disk seek penalties is becoming more important than avoiding the network hops that arise from using a shared cache.

While a server cannot handle an unlimited number of clients, it can serve many clients under typical workloads. In the case of overlapping requests from different clients, a shared cache on a shared server can outperform a series of unshared servers that each must retrieve the same data from disk, despite the overhead of network latency. Envoy is designed to move file management to the client's machine when there are no apparent conflicts, but to pick one participant to control files that are shared and act as a server to the others.

This principle of localising control where possible, but reverting to a simple, well-understood client-server model when sharing is necessary is fundamental to Envoy. It leads to fate sharing among clients with overlapping interests in the areas of performance, resource usage, and failure recovery. In each case, services with overlapping resource demands cooperate directly with each other and disinterested parties are not involved.

The overall distributed architecture of Envoy is based around partitioning control of the file system to put data and metadata management as close to interested clients as possible. Entire file system images or parts of images that are used exclusively by a single service (or a group of services hosted on a single physical machine) are managed directly by the envoy service on the same machine. Where sharing occurs, the client with the highest demand retains direct control and acts as a proxy for other clients accessing the same storage, thus sharing a single cache and avoiding complicated coordination protocols.

\subsection{Storage layer}

The objective of the storage layer is to provide a simple, stateless interface for accessing objects. The storage layer provides redundancy to enhance availability and reliability, and distributes objects to balance the load on individual servers. Like many of the cluster file systems described in \secref{sec:cluster-storage-systems}, Envoy uses an object-based interface to storage \cite{factor}. Disk layout policies are left to individual storage nodes, and replica placement is left to the storage system. \figref{fig:envoy-vs-storage} depicts the connectivity between the Envoy file system layer and the object storage system layer. Envoy servers actively connect to each other to form a coherent service, while stateless storage servers are passive, waiting for data requests and functioning as independent nodes.

\begin{figure}[t]
\centering
\includegraphics[width=\figwidth]{figures/envoy-vs-storage}
\caption[Network layout of Envoy and storage servers]{Envoy service instances connect to each other when necessary to form a single distributed service. Storage servers are stateless and act as independent nodes. All connections are direct, with no network overlay structure. In practice, both services are hosted on the same set of machines.}
\label{fig:envoy-vs-storage}
\end{figure}

Envoy puts a memory cache and a persistent disk cache between the object storage layer and the file system layer. File system traces show that with large caches, the operations that go to storage are dominated by writes and non-sequential operations \cite{ruemmler}, and traditional layout optimisation in layered systems is of questionable value \cite{stein05}, so the envoy layer does not take an active role in object placement decisions.

Numerous strategies are available for distributing objects across the cluster, including random distribution, chained declustering \cite{hsiao}, partitioning based on object ID ranges, collocating objects created together, etc. These can be managed through a separate service \cite{gibson98a}, by storing maps on the servers and caching lookup tables on the client nodes \cite{lee96}, or by using a mapping function that allows clients to compute the appropriate storage server based on the object ID and other metadata \cite{weil06}.

The contributions of this dissertation are at the file system level, not at the object storage level, so the details of object storage are omitted here and readers are referred to the relevant literature as discussed in \secref{sec:cluster-storage-systems}.

\subsection{Envoy layer}

The envoy layer forms a file system from the objects provided by the storage layer, coordinating and caching access to the file hierarchy, and exporting a client-server protocol to client services. The entire cluster shares a global, hierarchical namespace, but clients typically mount a subtree from the hierarchy and treat it as a complete file system.

\subsubsection{Territories}

A single instance of the envoy service runs on each physical machine, and the global name hierarchy is divided among participating instances in the cluster. When a given instance takes responsibility for some part of the namespace, it is said to \emph{own} a \emph{territory} covering the relevant subtree of the hierarchy, as illustrated in \figref{fig:territory-structure}. All operations within local territories are handled locally. Storage objects may be cached locally both in memory and in the persistent cache, which is used exclusively for territories local to the machine.

\begin{figure}[t]
\centering
\includegraphics[width=\figwidth]{figures/territory-structure}
\caption[Territories partitioning the namespace tree]{Envoy's namespace is hierarchical, and participating machines claim branches of the tree as \emph{territories} to be managed locally. Branches within a territory can be split off into new territories to be managed by a other machines. The overall system structure is a federation of territories.}
\label{fig:territory-structure}
\end{figure}

This partitioning of the global namespace and the resulting federation of constituent parts is what gives Envoy its name. When clients request operations that stray from local territories, the requests are handed off to the envoy on the appropriate machine. It follows that each instance must know not only the boundaries of its own territories, but how to find the envoy for neighbouring territories, i.e., those that can be reached by a single directory traversal (up or down) from a local territory.

The envoy service is stateful, and tracks not only its territories and neighbours, but the state of all files and directories in use by its client services, as illustrated in \figref{fig:envoy-territories}. When a client navigates beyond the boundaries of a local territory, requests are forwarded directly to the envoy that owns the neighbouring territory. If further navigation moves beyond the boundaries of the neighbour's territories, the neighbour does not forward it to the next envoy, but instead bounces the request back to the originator with the address of the envoy that can answer the request.

\begin{figure}[t]
\centering
\includegraphics[width=\figwidth]{figures/envoy-territories}
\caption[Territories and file handles]{Files that are part of locally-owned territories (enclosed in boxes) are accessed directly, while those in remotely-owned territories are accessed through forwarded requests. Envoy instances connect to each other when they have shared territory boundaries, or when one is forwarding requests for a file in the territory of another.}
\label{fig:envoy-territories}
\end{figure}

Under this system, two envoys maintain a direct relationship with each other only when they are immediate neighbours in territory ownership, or when one is serving requests for a client of the other. It follows that if territories are alloted such that the owner of a territory is also its most active user, traffic on an envoy instance will generally be dominated by its local clients.

Often, the best that can be achieved in a steady-state system is to have the owner of a territory be the envoy driving a plurality of traffic, not a majority. Sometimes this is an inevitable consequence of overlapping client demands, but often some further gerrymandering of the territory boundaries can improve access locality. Since the needs of the clients and the needs of the envoys are generally aligned, a practice that in politics usually serves those in power at the expense of those they represent serves both equally well in file systems.

\subsubsection{Files}\label{sec:directory-format}

Files and directories can be mapped easily to objects as provided by the storage layer. Files are stored as objects with a set of attributes, and directories as files with special semantics and a different interface. Special files are stored as normal objects with special contents, accessible through the interfaces appropriate to the file types.

Unix file systems are organised around \emph{inodes}, which organise the contents of a file and its attributes, but not its name. Envoy employs a similar structure, with file contents and attributes separate from the name hierarchy. Objects have numeric identifiers like inodes, but a file can be backed by different objects during its lifetime, so an object ID is not suitable for directly identifying a file.

Directories are files containing listings of other files. In Envoy, directories are managed at the block level, with each block containing some number of entries. An entry consists of a file name, the object ID that links to its contents and attributes, and a flag indicating the file's copy-on-write status. When this flag is set, the object is considered read-only, and will be cloned before any changes are committed to the file's contents or attributes. This process is completely opaque to clients.

Special files, such as device nodes and symbolic links, are stored as regular files whose contents follow a defined format. For symbolic links, the file contents are the target of the link, for devices they are an ASCII string identifying the major and minor device numbers, etc.

\subsection{Caching}

The cache in a distributed file system must balance performance with consistency and durability. While maintaining a coherent view of the file system that is tolerant to software and hardware faults, a cache should reduce latency, improve throughput, and increase overall capacity. The latter is achieved by reducing network and disk congestion and freeing input/output channels to absorb additional load.

Enhancing performance is the primary reason for employing a cache in the first place. The growing gap in performance between main memory and disk makes effective cache management critical, as a random disk access is five or six orders of magnitude slower than a similar memory access. The service cluster environment does not provide much insight into the expected access patterns of its constituent services, as one of the purposes of the environment is to support arbitrary clients. While application-specific cache hints are not available to aid in cache replacement decisions, service clusters do imply many file system images with overlapping content. Many images are private to a single client, while others may be accessed by multiple concurrent services.

In a 2002 interview, Eric Schmidt of Google observed that for seek-intensive workloads, DRAM can be cheaper to deploy than disks \cite{spring}. The seek time of a single disk cannot be improved significantly, so increasing disk performance requires adding redundant spindles. With many mirrored disks, many seeks can proceed in parallel and a random request can be satisfied fastest by the disk whose head position happens to be nearest to the requested datum. Because of the large performance gap, Google found it cheaper and faster to store their entire web search index in DRAM, which can serve many requests quickly, than to create enough replicated disks to handle the same transaction load.

While Google's implementation revolved around an inherently parallel task \cite{barroso03}, it can still inform the design of a cache solution for Envoy. A single, commodity machine cannot hold as much memory as would be required for an index of the web, but by considering the aggregate capacity of a cluster instead of focusing on the capabilities of a single machine, they arrived at the surprising but sensible conclusion that ``it costs less money and it is more efficient to use DRAM as storage as opposed to hard disks''. Finding data in a local cache is ideal, but with a high-speed network connecting machines in a cluster, it is faster to query the cache of another machine than a locally-attached disk \cite{dahlin94b}, suggesting that it would also be prudent for the design of Envoy to rely on the combined cache of the cluster as well as the cache of individual nodes.

Envoy is designed to compromise between the competing goals of maximising local cache hit rates and maximising the aggregate cache capacity of the cluster. Two design features are particularly relevant to addressing these goals. The first is that all client requests are served synchronously by the envoy service without the aid of a local cache. Instead they rely entirely on the shared cache hosted by the envoy service in its private virtual machine. The local envoy directly services all requests---local and remote---for territories it owns, so the entire cluster caches at most a single copy of a given file. Multi-level caching is most effective when lower levels are significantly larger than higher levels (as with the persistent cache compared to the in-memory cache), otherwise the lower level ends up shadowing the higher level and contributing little to overall hit rates \cite{muntz}.

This could potentially strain the envoy that owns a particularly popular file, as it funnels all traffic for that file to a single node. For light to moderate sharing, this is not an issue, and in practice the envoy will be accessing the file mainly from its cache and can handle significant traffic. For extreme instances of sharing, services should use explicit network-facing protocols instead of relying on the file system as a poor man's distributed shared memory system.

The second design feature has a more complex impact on the aggregate cache capacity. Territorial borders are drawn along boundaries in the namespace hierarchy, but because of the copy-on-write mechanism in snapshots and file system forking, multiple names may refer to the same underlying storage layer object. This only happens when the object (but not necessary the file) is read-only, so cache consistency need not be considered, but it does mean that multiple envoys may cache the same underlying object. While this mechanism introduces redundancy in the cluster-wide cache, it also has the potential to consolidate cache entries within a single envoy instance. If multiple file system images have files backed by the same object, they will occupy the same place in the persistent cache as well as the in-memory cache.

Cache utilisation is most effective when clients on a single machine use file system images forked from a common template, and the more complete the template image the more likely it is that services will rely on common rather than custom-installed files. This fits nicely with the stated goals of flexible commodity computation, where both the host and the client gain from using the most popular commodity tools. The host by reducing client footprint and increasing capacity, and the client by reducing deployment costs and maximising performance through increased cache hits.

\subsection{Data paths for typical requests}\label{sec:data-paths}

\begin{figure}[t]
\centering
\includegraphics[width=\figwidth]{figures/request-paths}
\caption[Possible data paths for an individual operation]{Individual requests may be filled through one of several possible data paths, each with higher latency than the last. High-latency paths are designed to be less common than low-latency paths, and Envoy introduces caching and dynamically re-arranges territories to reduce the average data path length.}
\label{fig:request-paths}
\end{figure}

To summarise the architecture of Envoy, consider the data paths followed by typical file system requests. The best case is retrieval from in-memory cache on the same machine and is designed to be the most common. Extra steps are required in progressively less-common operations until the worst case, where a request travels from a client to the local envoy service, is forwarded to a remote envoy, misses the local cache and is forwarded to a storage server instance where the data is retrieved from disk. This sequence is summarised in \figref{fig:request-paths}, and depicted graphically in \figref{fig:hops}.

\begin{figure}[t]
\centering
\includegraphics[width=\figwidth]{figures/hops}
\caption[Network paths taken by typical file requests]{File system requests proceed from service VMs to the local envoy service. A request from a local territory may be filled by the local in-memory cache, the local disk cache, or by a single network hop to a storage server. A request for a foreign territory adds a single network hop in each case, as the local envoy acts as the client to a remote envoy.}
\label{fig:hops}
\end{figure}

\subsubsection{Read operations}\label{sec:data-paths-read}

The best case is a request for hot data in a local territory. In this case, data can be served from the in-memory cache of the local envoy server. With a fully optimised implementation using Xen or a similar VM environment, this data transfer can occur with a single data copy from the cache to a data page, and that page can then be swapped directly to the client VM via page table manipulation. Since the client's OS does not keep a cached copy, that page can likewise be passed on directly to the client application. While the prototype is not this optimised, the design permits a very lightweight operation involving a single data copy and some metadata manipulation.

Warm data from a local territory follows a similar path, prefaced by retrieving the requested data from the local persistent cache (on disk) into the in-memory cache. With large, cheap commodity disks, the persistent cache can easily hold several operating system images and typical application suites. Typical Linux installations occupy no more than a few gigabytes, and even that includes many supporting files that are rarely used and may never be referenced in common service deployments \cite{gibson98b}. If services have forked from standard base images as proposed, it is realistic to assume that most operating system and standard applications files will be available in the local cache hierarchy for a service being deployed on an active node \cite{klosterman}.

When the local cache fails to deliver, the envoy service must retrieve requested data from the storage layer. In the prototype the persistent cache holds only complete objects, so an entire object must be transfered before the envoy service can begin fulfilling requests from the local cache. If the object is replicated, it can be retrieved through parallel transfers from multiple storage servers for higher throughput. The cache implementation could also be refined to store ranges of bytes instead of just entire objects, which would complicate bookkeeping but permit faster access to partially-transferred files. It would also allow partial caching for files that are too large for the cache. Sequential access to large files merely scrubs the cache when using a least-recently-used eviction policy, but other access patterns could benefit from caching regions of the file, and non-sequential access to large files is becoming more common \cite{roselli}.

Operations in territories outside local control add an extra network hop between the local and remote envoys for all operations. The data is not stored in the local cache, so locality of reference does nothing to remove this network penalty. It does offer another optimisation opportunity (the data, once received from the network, can be passed to the client application without any further copying) but this is minor compensation for a guaranteed latency penalty.

Fortunately, this penalty need not be too great nor too common. The remote envoy handles the request just as it would one from a client local to it, including caching, so referential locality does improve performance from the cold- and warm-cache cases. In addition, service clusters have high-speed local area networking across switched connections. Finally, because of the way territories are decided, in a steady state system foreign envoy requests generally imply some degree of sharing. While relatively uncommon in itself, runtime sharing requires \emph{some} form of synchronous network communication to guarantee consistency, so Envoy's goal of reducing synchronous inter-node traffic to cases of either concurrent or infrequent access seems a reasonable one.

\subsubsection{Write operations}\label{sec:data-paths-write}

Write operations are less common than reads, but much of the complexity in file system design comes from supporting them. While a good cache satisfies many read requests from memory quickly and with no correctness concerns (provided coherency is maintained in the case of distributed systems), write operations cached in memory raise concerns about durability. If the server acknowledges a write operation as being complete but has only committed it to an in-memory cache, then there is a window of vulnerability before the data is stored to disk. If the system crashes in this time, it will lose data that the client expects to be resilient to crashes. In an isolated client, this may be acceptable. The client will simply be forced to restart from the state that was committed to disk and will lose a bounded amount of work. It is particularly problematic for distributed systems and others with external side-effects, however, where other participants may cue subsequent actions on the premise that a write has been successfully and durably committed to disk. The problem is further exacerbated in a commodity hardware environment where failures are routine.

At the other extreme, one can commit all writes to disk before completing the transaction. This makes it clear to the client when a write operation has been consummated, and it is free to either wait for the acknowledgement or proceed asynchronously with explicit knowledge of the risk it is assuming. While this is a simple and appealing model, it ignores two important realities. The first is that the default action for most commodity operating systems is to cache writes and acknowledge them immediately while delaying the disk write. Changing the expected performance characteristics of a basic operation like writing to disk would severely affect the performance of many standard tools in a negative way and not provide an environment friendly to commodity software. The second is that most files created are short-lived temporary files that are soon deleted \cite{ousterhout}, so synchronously writing them to disk introduces not only unnecessary latency but also unnecessary disk contention.

Several intermediate possibilities exist. Instead of having write requests proceed directly to the storage layer, the local persistent cache could be used as a staging area, with write requests being committed locally and then forwarded to the storage layer after some delay. This would do little to improve performance, however, as synchronous disk access is slower than synchronous network access, so this would not eliminate the slowest link in the event chain. Specialised hardware with involatile memory could also act as a staging area, giving good write performance while retaining durability. The latter approach violates our goal of using widely-available commodity hardware, however, and neither approach is resilient to hardware faults that result in the entire node failing.

Another approach is to only guarantee synchronous durability when explicitly requested by the client, using the equivalent of the Unix \texttt{fsync} system call. This matches the semantics of local file systems, and thus what most software is written to assume. It is not without faults, however, as the popularity of high-level scripting languages and middleware frameworks (especially for network services, exactly the types of clients service clusters are designed to support) means the connection between application actions and disk operations is often obscured. Requiring low-level controls to get correct behaviour may be a popular compromise, but it is not ideal. Recent results suggest that the latency of synchronous writes can be effectively hidden by the operating system, supporting the choice to support synchronous semantics at the distributed system level \cite{nightengale06}.

The solution Envoy employs is based on exploiting the cluster environment. While commodity hardware is expected to fail occasionally, simultaneous failure of multiple machines is still rare, provided that the nodes are sufficiently isolated from each other in terms of power and cooling. Since service clusters are intended for professional hosting environments, it is reasonable to assume that hardware faults occur in isolation. With that assumption, durability is less about committing data to disk and more about redundancy. A write request is considered final when it is in the memory of all of the storage servers that will eventually commit it to disk. If the envoy server fails, the storage servers are unaffected. If one or more of the storage servers fail before committing the data to disk, the recovery mechanism must restore consistency using the most up-to-date of the replicas. Having storage servers potentially out of sync due to a failed asynchronous write in this scenario is fundamentally no different from having one fail while trying to satisfy a synchronous request. In both cases, the inherent asynchrony of the network means that replicas may be out-of-sync with each other. Only the degree of the problem changes. This scheme allows temporary files to be written and deleted before reaching the disk, but does not do so by gambling with durability for some arbitrary time window, which may or may not be suited to the client's workload \cite{roselli}.

\section{File system images}

A single, hierarchical namespace unites all the participants in an Envoy cluster, but for management purposes there are two distinct levels. The administrative file tree starts at the root of the namespace and has as its leaves the file system \emph{images} that are normally accessed by clients. Imposing this additional structure in the tree codifies the intended usage pattern, which simplifies administration and allows for some simple but effective optimisations.

\subsection{Security}

Service clusters must accommodate a heterogeneous collection of clients, some of which may trust each other, but most of which do not. To support standard operating systems and tools, Envoy must support familiar semantics, including granting complete control over private images, while also accommodating shared images that grant limited access to various clients. In addition, clients themselves may wish to arbitrate access to shared storage, rather than expecting the cluster owner to manage credentials for any combination of services.

\subsubsection{Enforcement}

Simple security is one of the benefits of the service cluster model. Physical machines are controlled by trusted software that isolates clients from each other and from the administrative tools. Hosting the cluster in a managed environment similarly secures physical access to the machines and makes a trusted environment possible. Virtual network devices connect client VMs within a machine, and they also route network packets from clients to the rest of the cluster and the outside world. With well-defined and controlled boundaries, packets cannot be spoofed within the cluster and network addresses can be an accurate and reliable indication of the origin of network data.

For Envoy, this means that client access to the file system can be strictly isolated to the client-server interface exported by a client's local envoy. The clear lines of trust provided by the environment make enforcement of security policies relatively simple. Envoys communicating with each other can be authenticated by their network address as well as by the credentials they provide, as can connections between envoys and storage servers. Encryption of traffic is possible, but since the cluster contains only trusted machines, the threat of packet sniffing is much less than in other environments.

\subsubsection{Policy}

Access to files is controlled at two levels. The first governs entry to the file system. When a client mounts a directory, be it a file system image or an administrative directory, it supplies its credentials and a pathname relative to the global root of the file hierarchy. The supplied credentials determine the client's identity and maximum privilege level for access to the requested directory and all of its descendents. The second level manages access to individual files according to the identity the client supplied at mount time and the permission attributes of the files.

Administrative directories support all normal file operations, and configuration is done through ordinary files with special formats and naming conventions that are recognised by the envoy service. A credential file can grant access to descendents of the directory that contains it, descendents that may be image roots or further levels of the administrative hierarchy. Permission granted at one level cannot be revoked at a lower level; credentials are established at mount time and are unaffected by subsequent configuration changes. Special files lose their meaning within file system images, so credentials apply to entire images or groups of images.

A noteworthy feature of this system is that clients can manage their own stable of images and the credential files that govern access to them. A set of mutually-trusting clients can share a single credential file and a pool of images with minimal structure, or a client can create a deeper hierarchy of images with fine-grained credentials granting limited access to less trusted clients. A client's credentials may specify its identity or permit it to assume any identity at mount time. This lets Envoy arbitrate shared access between clients or grant them root-like control over the identity space of an image.

File-level credentials are stored as file attributes. A client's identity is established at mount time, and after that access follows the semantics of the client-server protocol used to access Envoy. Unix-style user/group/world permissions and fine-grained access control lists can both be stored as file attributes and enforced by the server. The system used by a particular implementation is largely determined by what the client access protocol supports. In the case of the Envoy prototype, the 9p protocol dictates Unix-style permissions. Depending on the credentials supplied at mount time, superuser privileges can be granted or denied to a client to support the Unix \texttt{root} user or emulate NFS-style root squashing \cite{pawlowski}.

A few examples are illustrated in \figref{fig:image-credentials}:

\begin{description}

\item[(a)] The cluster owner creates a variety of templates with well-known operating system installations and grants all clients access to fork them as needed. He gives clients individual credentials that give them control over a private branch of the namespace, which they can use as they see fit. Clients can retain exclusive access to their branches, or they can create new credential files to control sharing among their own VM instances and between other clients in the same cluster.

\item[(b)] An isolated client registers with a host and is given credentials granting full control over an empty administrative directory. In addition, credentials are supplied that let her fork several image templates, access that is equivalent to letting her mount those templates as a read-only user. She forks a Linux distribution and assumes root privileges over what is now a private image. After configuring the image, she forks it again to support two cooperative VMs. User accounts on her virtual machines access storage through the kernel, which uses her single set of master credentials to authenticate any arbitrary user, but mounts them as individual users with access limited according to Unix-style permission control.

\begin{figure}[t]
\centering
\includegraphics[width=\figwidth]{figures/image-credentials}
\caption[File system images and credential files]{Credential files give clients control over access to images and assignment of user IDs. Within images, normal file system semantics govern access to individual files. (a)~This two-part access control lets cluster managers grant limited access to template images while giving clients control over their own branches of the namespace. Clients can use their own credentials or grant more limited control in their own hierarchies. (b)~Clients may use their own credentials to access images, (c)~create their own custom templates for resale along with shared data areas, or (d)~create a mixture of private images and shared images.}
\label{fig:image-credentials}
\end{figure}

\item[(c)] A service provider starts with a similar empty directory, but creates a few levels of directories. He, too, forks a Linux distribution, but customises it with applications fully configured to support a specific kind of server. He forks his own images to prepare several variations that will be useful for different clients. These images are collected under a single directory, where he creates a file with custom credentials to give his clients access to fork the templates he has prepared. In addition, a different directory with different credentials governs access to a shared image that his clients use to share data with each other. They can mount the shared image with limited access, but they can get full read-only access to the templates, or fork one and assume full control over the copy.

\item[(d)] A distributed service starts out with the same empty directory. The manager prepares a custom template from a forked FreeBSD image, then forks it many times for different instances of the service. Each instance is assigned randomly-generated credentials that give it full control over a single cloned image, limited access to a shared data image, and nothing else. Each private image is housed in its own directory to isolate credentials, but all of those directories can be accessed by the manager with her master credentials.

\end{description}

Client-owned hierarchies can be used to support many scenarios, from simple single-user images to complex interactions between different clients with limited trust. Templates can be customised and shared, and images can be opened for sharing with client-configured but Envoy-enforced access limitations, or clients can take full control of images and grant access to data through their own network-facing protocols. Flexibility is derived from enforcing normal file access semantics, but letting clients control access to images and manage the assignment of identities within those images. Client-managed credentials can apply to administrative directories as well, letting cluster users further delegate management responsibilities to their own clients.

\subsection{Forks and snapshots}\label{sec:snapshots}

To support the rapid deployment of services, standard installations of commodity operating systems and software can be provided to clients as a starting point. This is accomplished in Envoy by creating a small set of well-known template images and allowing clients to fork them as a starting point for their own private images. Using copy-on-write techniques, many clients can diverge from a single image, sharing unchanged files and consuming resources only for the changes made.

The copy-on-write mechanism in Envoy works at the level of an object in the storage system. Files and empty directories are leaves in the object tree, with non-empty directories acting as interior nodes that branch out. Modifications to privately-owned objects can be made directly to those objects, but changes to a shared object can only be made by cloning it and applying the changes to the copy.

An object clone has a different object ID than the original, so directory links to the object must be updated, which in turn may require cloning the directory object. Changing a leaf in the file system tree requires cloning a path from a writable ancestor to the object itself, a process that resembles modifying an immutable tree structure in a functional language: an entirely new tree is produced that links back into the old tree wherever possible.

\subsubsection{Image versions}

While snapshots could be taken at any point in the file hierarchy, a few additional rules simplify management. The root of the namespace is always writable, as are all administrative directories, i.e., those that are not descendents of a directory whose reserved name marks it as an active image root or a snapshot of one. Existing snapshots are always immutable, and new ones can only be taken from the root of an image, not from arbitrary points in the client's directory structure.

A new image is started by creating a specially-named directory in an administrative area that does not already contain an image. Naming conventions distinguish the active version of the image and identify its snapshots. The naming scheme restricts the history of an image to a linear series of snapshots taken over time. For management purposes, the entire collection is considered a single image with an active head and a series of historical versions.

\subsubsection{Forking an image}

The word ``snapshot'' implies that a copy of the state of an image is frozen and set aside as though an external observer captured a view of the entire active system, but in reality it is the active version that is frozen and set aside, while a newly-created head takes the place of the old one and diverges from it over time. The continuity of the active image is preserved through sleight-of-hand as active file state is transparently transferred from the old head to the new.

The process of forking an image is the same, except that it starts with a snapshot already frozen as part of the history of another image. To fork a running image, a snapshot must first be taken, after which the forked image and the new head of the old image can both start from the same immutable tree and move forward independently.

\subsubsection{Snapshots and territories}

Because of the copy-on-write mechanism, changing a single file may require modifying a path all the way back to the root of the image, potentially crossing territory boundaries and involving multiple envoys in the process. This would violate the goal of local impact for normal file operations and complicate the protocol between envoys. To simplify matters, Envoy requires that the root of each territory be writable (unless it is part of a read-only snapshot). The worst case is reduced from cloning a path back to the root of the image to cloning a path to the root of the territory, making it always possible for write operations to be completed by a single envoy.

To satisfy this requirement, the snapshot operation must clone a path to each territory exit after freezing the territory. In practice this process works in reverse, starting at the leaves of the tree and working toward the root of the image. Child territories are frozen and their roots cloned, then parent territories are frozen and paths from their roots to their children cloned. Eventually, the root object of the image is replaced by a clone; the old object becomes the root of the snapshot and the new clone becomes the root of the active head of the image.

This process simplifies writes, but it also creates unnecessary cloning for territories that do not serve any write requests before the next snapshot. This is a tradeoff between simplicity of design and space efficiency. Cheap and ample disk space is one of the motivating advantages to using commodity hardware, so this tradeoff is consistent with the goals of the Envoy file system.

\subsection{Deleting snapshots}

Storage space is cheap and plentiful, and systems such as Venti are designed to keep a complete history of all files ever created \cite{quinlan}. This may be appropriate for some workstation environments, where the increase in storage capacity can out-pace typical data creation rates, but deleting files permanently is still a necessity for many other users. In service clusters, users are charged according to the resources they use, so they must have the flexibility to completely remove old files. Also, when clients leave a particular service cluster, the owner may wish to reclaim the space for future use, as there is little incentive to keeping it around on behalf of a client that is no longer paying. Also, concern for privacy and compliance with data retention laws may require data to be completely removed.

The only backups mechanism in Envoy is the snapshot operation. Since anything created and deleted in the window between two successive snapshots is no longer accessible anywhere, it is deleted immediately. This is easily detected through the copy-on-write mechanism, which identifies all files that were created since the most recent snapshot. All files with copy-on-write flags (either explicit in a directory link or implicit through an ancestor's link) are backed by objects referenced by one or more read-only snapshots, so envoys never delete these objects when their corresponding files are deleted.

The problem comes when trying to delete old snapshots, as it can be difficult to determine which storage objects are only referenced by that snapshot.

An obvious solution is to implement reference counting in the storage layer. This has the advantages of simplicity, accuracy, and immediacy. The main disadvantage is that it puts the performance burden in the wrong place: every time a directory object is cloned (a frequent operation when a snapshot is followed by write requests) the reference count of all objects in that directory must be incremented. This requires updating all storage replicas of all files in the directory, making the copy-on-write mechanism expensive in order to support an infrequent operation that is not timing critical.

The copy-on-write mechanism in Envoy is similar to the one in Parallax, as is the problem of deleting snapshots \cite{warfield}. The problem was simpler in Parallax, however, which uses a copy-on-write radix tree to map logical blocks to physical blocks in a virtual block device. The virtual block numbers do not change between snapshots, so comparing the physical blocks mapped to by two successive snapshots reveals which blocks from the first were unlinked during the lifetime of the second.

With Envoy and its hierarchical file tree, the problem becomes more complex. While it is still a simple matter to compare the object IDs of directory entries to detect changes between snapshots, it is harder to distinguish between the effects of objects being cloned and objects being deleted and created. In Parallax, the two radix trees are recursively walked in parallel, and changes always denote cloned blocks. In Envoy, files and directories can be renamed, so there is no easy way to match an object in an old snapshot with a cloned version of the same object in a newer snapshot. The static virtual block IDs in Parallax are replaced by variable names in Envoy, making the process of comparing two snapshots more difficult. Supporting hard links makes it even harder to define a one-to-one correspondence between object references in two successive snapshots, since multiple references may exist to a single object.

This potentially messy problem can easily be solved by brute force. Instead of imposing extra runtime overhead for normal file operations or attempting to walk two file systems and identify matching files within them, it is simple and practical to gather a complete list of objects referenced by an image. Using 64-bit object IDs, such a list takes 8~megabytes for every million files. A 1999 study of workstations at Microsoft found an average of 13,309 files on each of 10,568 machines, with the subset running NTFS (the newest file system studied and the one with the largest average number of files) averaging 24,229 files over 3,332 machines \cite{douceur99}. Average file counts will no doubt continue to grow, but anecdotal tests found the number still in the low millions for typical, modern desktop Linux installations.

Gathering a complete list of objects and sorting it for each snapshot makes the identification of object creates and deletes a simple matter of scanning two catalogues in order and finding differences. It requires some storage space to implement, but not much. Deleting snapshots is not a critical-path operation and for typical image sizes the brute force approach requires little enough space that that no amount of reduction would be worth more than a very small complexity increase.

This asynchronous process bears some resemblance to the cleaner of log-structured file systems \cite{rosenblum}, which asynchronously recovers disk space from the tail of the log. The snapshot-delete problem has a critical difference, however: Envoy runs in a cluster environment, where the asynchronous process can run on a different node to prevent the interference caused by the cleaner under some workloads \cite{seltzer93,seltzer95}. In addition, successive snapshots will typically have much overlap in the directory objects referenced, so the machine-level cache can absorb much of the traffic.

A sorted file listing all object IDs referenced in the snapshot can easily be stored in the administrative directory that contains the image. To delete a snapshot, the objects of it and its immediate successor and predecessor are compared in order. Each object that appears in the snapshot but disappears in the successor can be safely deleted from the storage layer. To make it safe and resilient to crashes, the envoy service ensures that no clients are currently accessing the snapshot, then it unlinks the root of the image first, and deletes the list of object IDs last. At recovery time, an object ID file found without a corresponding image indicates that a crash occurred before the operation completed, and it can be safely restarted. The image itself isn't necessary at this stage, and as long as the cleanup process can tolerate objects having already been deleted, it can work entirely from the object lists.

The only other complication in this process is image forks, where multiple successors may exist for a single snapshot. Forking an image does not directly affect the snapshot used as the starting point, so the easiest way to detect forks is to log them. The log is consulted before any snapshot delete attempt, and deleting images that have more than one immediate successor is not permitted.

A few other corner cases are worth mentioning. The current version of an image can be deleted using the same procedure, but it must be made read-only or client access must be disallowed before gathering the list of object IDs (note that access is normally only forbidden when deleting starts; the catalogues of predecessors and successors must be assembled as well as those of images marked for deleting, but normal access can continue during this process). Otherwise, the normal procedure suffices, with the successor object catalogue taken to be empty. The log of image forks must also account for deletes, so that entire trees of images can eventually be pruned back to the root if desired.

\section{Territory management}\label{sec:territory-management}

The Envoy file system model is based on the idea of presenting a single, large file tree connecting arbitrary images, but providing incentives to use it in ways that can be exploited to provide good performance and scalability. The service cluster model makes it simple to isolate control of the file system from the clients who use it, while still keeping synchronisation logic and caching on the same machine most of the time. Providing a global namespace gives a great deal of flexibility, but inferring usage patterns and collocating ownership of branches of the tree with the clients that use them yields short data paths and good performance.

\subsection{Design principles}

A variety of approaches to distributing territory ownership are possible, and only a realistic usage model drawn from empirical study of real-world deployments can accurately inform optimum choices. Lacking that, territory management in Envoy is designed with a few goals in mind.

The first is to favour optimising long-term patterns over tracking short-term trends. High-speed switched networks minimise the penalty for serving a request from a remote envoy compared to handling it on the client's envoy, and the growing gap between memory and disk performance makes flushing the cache to support a territory realignment continually more expensive. Based on this and on the past success of client-server file systems, Envoy favours slow evolution of the namespace topology to capture steady-state client behaviour. Instead of attempting to track each change in runtime usage patterns, it offers a client-server model that gradually optimises itself over time by collocating servers with clients.

The second is to avoid complexity whenever possible. This applies to the runtime behaviour of the system as well as the algorithms and implementations that drive it. For debugging, recovery, and runtime analysis, territories with simple boundaries that do not change frequently are preferred. Painting control of the namespace tree in broad strokes makes it easier for humans to comprehend and analyse, minimises perverse cases that can threaten correctness and the success of recovery operations, and makes global logging of changes practical. With this in mind, Envoy favours using a few territory divisions to give good results over making many divisions in an attempt to approach optimal results.

\subsection{Special cases}

Token passing is a popular way to coordinate access to file system objects. Before a client can access a file, it must be granted an appropriate \emph{token}, and the token must be transferred to a second client before it can operate on the same file. Multiple reader/single writer tokens may permit some concurrent access, but synchronous token transfers are frequently necessary before a request can be satisfied. While these operations can be optimised, fundamentally they operate on a pessimistic model analogous to locking in shared memory schemes.

Territories in Envoy are related to leases and token systems, but they are based on an optimistic model where large groups of files can be granted to an owner on the assumption that sharing is uncommon. Synchronous token transfers are avoided; every request from a client can be processed immediately either by the client's envoy or by a direct, already-established link to the owner, with complete access to the owner's cache. Performance is best when the territory's owner is on the same machine as the client, but because of the cluster environment the penalty of an extra network hop for remotely-owned territories is not excessive.

The decision to cede all or part of a territory to another envoy is always made by the current owner. While a client's envoy may be able to recognise the client's ongoing demand for a particular region of the file tree, only the envoy that manages it can account for all clients that are accessing it and act based on complete information. Territories form a tree overlaid on the file system tree, and territory transfers are always driven by the parent of the territory being transferred. The parent only initiates a transfer when the owner of the territory requests it, leading to the first special case in territory realignment: when a territory is dormant, it is ceded to its parent. Dormancy is determined through the general mechanism described below, but this is highlighted as a special case because no other envoy can detect a territory that has fallen out of use. Territories are also ceded when an envoy is shutting down.

Another special case is based on the expectation that most images (especially those used as boot images) will be used by only a single client: when a client mounts an image that is not in active use, the image is immediately ceded to that client's envoy. The first client to mount an image may not be the one that will use it the most, and the dynamic algorithm would sort it out eventually anyway, but this heuristic avoids a warm-up period of degraded performance for the most common usage pattern. For services with no sharing, this is sufficient to completely localise non-administrative traffic. This is also an example of how imposing a little structure on the file tree can not only simplify administration, but also improve performance.

\subsection{Dynamic boundary changes}

Control of a private image is handed over to the relevant envoy when the client mounts it, but control of shared images is initially given to the \emph{first} client to access it, which may not necessarily be the heaviest user. Envoys observe the access patterns of their local clients and compare them to forwarded traffic from remote envoys, periodically ceding control of parts of territories, or even handing over control of an entire territory in an attempt to improve locality of access.

Territories are transferred in response to observed usage, with one of two goals: to improve locality or to simplify the territory layout. The latter occurs when traffic to a territory falls below the \emph{idle threshold}, and the benefits of local ownership are not considered worth the extra cost in topological complexity. In this case, the territory is handed to the neighbouring envoy with the most boundaries in common with the old owner, either the parent or the owner of one or more child territories.

Traffic is monitored by the number of requests from each remote envoy, with all client requests combining to form the owner's contribution. A single value for each participant is computed as the total number of requests, exponentially decayed over time with a configured half-life. This approach allows envoys to continually monitor load and react not only to the presence of imbalances, but to their severity as well. Sub-optimal layouts are addressed more urgently when traffic volumes---and the potential benefits of optimisation---are high, with a slower response given in low traffic, where waiting can confirm that the trend is lasting and that a fix is likely to be worthwhile.

For simplicity, only a single new territory is created in each realignment; if two branches of a territory need to be ceded to a remote envoy, they will not be combined into a compound transfer, but will instead be evaluated and transferred independently. To aid in accurately predicting the effect of a given transfer, the traffic value for a directory combines requests for its descendents with those for the directory itself. To the extent that recent traffic trends continue, the combined traffic values for a particular object summarises the overall effect of ceding it as the root of a new territory.

For each object in a territory, the owner considers ceding a new territory rooted at that object to each envoy that has driven traffic to that branch. The harm to the local envoy and the benefit to the remote envoy are weighted equally by subtracting local traffic from that envoy's traffic, yielding the expected benefit of the transfer. Requests from third-party envoys will be unaffected, as they will just be transferred from one remote envoy to another. In this way, the expected benefit of each territory change (including transferring control of the entire territory) can be considered and compared with the alternatives.

Before actually initiating a transfer, two conditions must be met: the transfer must be the one that will yield the maximum expected benefit, and the urgency of the proposed change must be sufficient to justify the disruption of a boundary change. A highly beneficial transfer is considered urgent, but if the improvement is modest then it is delayed to encourage stability in the topology and discourage thrashing of the cache. A simple linear scale has the urgency requirement decreasing as time elapses since the most recent boundary change affecting the envoy. A minimum delay and the idle threshold guard against extreme cases.

Scanning an entire territory after each request would be prohibitively expensive, but the scheme outlined here can be approximated in a straightforward fashion. As each request is recorded and the traffic value for affected objects updated, the envoy computes the expected benefit of transferring that object to the originator of the request. This process is repeated as the request is recorded for parent directories all the way to the root of the territory. The maximum benefit observed is compared to the time elapsed since the most recent transfer, and the envoy decides if a new transfer is warranted.

With this implementation, a transfer that was rejected at the time of a request for insufficient urgency may become viable as the territory ages, and the envoy will not notice it in the absence of a new request to trigger a re-evaluation. While this violates a strict interpretation of the procedure, it does so only in the absence of traffic from the remote envoy, a condition that casts doubt on the efficacy of the transfer anyway.

\section{Recovery}\label{sec:envoy-recovery}

Putting commodity computation in a managed environment with well-provisioned hardware reduces the rate of node failure, but all computer systems are subject to the hazard of failure, whether from hardware faults or software problems. A viable recovery procedure is essential for any storage system, and minimising the disruption to other nodes is also important in a cluster environment.

The controlled environment has its advantages, however, in that the expectation of failure for a given node is low enough that it can be treated as an exceptional condition, rather than a routine part of operation. This stands in contrast to distributed systems running on machines owned and managed by a wide range of people, whether peer-to-peer systems on volunteered machines or networks of workstations in a corporate environment, where the needs and habits of the node owners preempt the interests of the whole system.

As a commodity platform, failure of an individual node can reasonably disrupt the services running on it. Uptime guarantees and other reliability requirements must come from higher-level services, which may be implemented as a series of clients on a service cluster or across multiple clusters. The latter is necessary for the most stringent requirements anyway, since catastrophic failures such as natural disasters may affect all machines at a location no matter how well cared for. Since prevention of failure is impossible, and failover capabilities for all clients would be complex and expensive, a more practical approach is to assume that nodes will occasionally fail, and seek to minimise the disruption to the rest of the cluster while restoring the service of the lost node as quickly as possible.

The basic assumption implicit in Envoy's recovery model is that the failure of a machine or any of its parts (including management software) may result in lost service to the clients hosted on that machine. Moving outward, envoys that were interacting with the failed machine should be able to recover fully with some disruption, while nodes with no overlapping interests should be unaffected.

The other philosophy that drives failure recovery is that it should be as simple as possible. Recovery scenarios are both difficult to predict and difficult to simulate. In a distributed system, interactions involving multiple participants can be complex enough when they work, and an unanticipated failure at an unexpected time can often lead to conditions that are hard to anticipate. Enumerating cases that must be handled is an error-prone process that can become intractable with too many sources of faults. Even when complex failure cases are correctly identified, simulating them under realistic conditions to test equally complex recovery code is another difficult and error-prone process. Ongoing field testing is dominated by correct behaviour (one hopes) so recovery code is rarely exercised as well as normal code paths. Finally, because recovery procedures are only invoked in response to failure, they represent the last line of defence against lost data and the last chance to retain the trust of users, a critical element in storage systems.

Some of the most successful systems reflect these concerns. Database systems typically log transactions in a simple, append-only structure before applying changes to complex data structures. At recovery time, no attempt to diagnose the exact conditions of failure is necessary---instead the log can be replayed to complete committed transactions or even resume an interrupted recovery process. Similar journaling schemes are increasingly common in modern file systems for many of the same reasons. Careful ordering of writes can ensure that a crash at any stage leaves the system in a sane state, offering the same principal benefit: recovery from a wide range of failure conditions can proceed even without knowing what actually caused the failure.

\subsection{Prerequisites}

Some amount of redundancy of runtime state is necessary to allow complete recovery after a node failure. The fate of a client is already tied to that of its local envoy, so envoys track the state of all active file handles for local clients, including those files that are owned by remote envoys. The local envoy acts as a proxy server for remote files, so it can easily peek at request and reply messages to observe state updates. For local and remote file handles, an envoy tracks the full pathname of the file, the user credentials used to access the file, and any state related to file status and position required to support the client-server protocol used by the client.

A client's envoy can track its file handle state locally, but file data is not duplicated for forwarded requests. Duplicating runtime state can prevent disruption, but preventing data loss requires redundancy in written data and attributes. The write-through persistent cache in Envoy answers this requirement by ensuring that data has reached the storage servers for all replicas before reporting a write operation as complete. As long as enough storage servers are able to write the data to stable storage, the crash of an envoy node will not affect the stability of data, nor its immediate availability to the recovery process.

Depending on the storage layer implementation, a window of vulnerability may exist between the time the first and last storage servers have been notified of an update, during which an envoy crash would result in an inconsistent state between replicas. The problem resembles that of a storage node failure, and in both cases recovery of the storage node would necessitate it ``catching up'' with missed transactions. This is fundamentally a part of the storage layer design, not part of the envoy service.

\subsection{Recovery process}

With runtime state and file data available, it is possible for envoys that were interacting with a failed node to recover fully from the disruption, with temporarily degraded performance as the only effect visible to clients. The affected envoys include all those with which the crashed node had any kind of relationship, including the owners of the parents of its territories, the owners of the children of its territories, remote envoys accessing files in its territories, and remote envoys to which it forwarded requests for local clients.

The first step in recovery is recognising that something has gone wrong. Envoys monitor the status of their neighbours in the territory tree as well as that of the envoys with which they share files. These connections can be monitored closely without imposing a significant burden on the network, as they are always unicast messages between small sets of hosts. Normal interactions can double as heartbeat messages most of the time, and explicit messages are only necessary on otherwise idle connections.

Once a node fails, the territories it owned and their descendents are immediately dissolved and annexed into the parent territory. In-flight operations no longer act under the authority of a territory owner and are suspended. Forwarded operations between two otherwise-healthy envoys are rejected with a suitable error so that the client's envoy is made aware of the failure. Parents notify children recursively, resulting in a pool of envoys that hold file handles for their clients but have nowhere to send transactions. The envoys then reconnect each file handle to a territory owner by walking from the root of the file system tree to find the new owner. Unlike normal directory navigation requests, these traversals always succeed, even if directory permissions have recently changed. Envoys can nominate themselves to reclaim ownership of territories, or they can leave it to the normal demand-driven process to sort out boundaries over time.

In keeping with the goal of simplicity and blanket coverage of failure cases, this handles failures that occur in the middle of territory ownership transfers as well as simpler, steady-state cases. The canonical version of the file tree is maintained by the storage system, not by the soft state of territory ownership. Once the ownership tree is corrupted by a failure, the corrupt branch is pruned and re-grown from its former root. Similarly, the canonical version of a file handle is maintained by the client's envoy, not by the territory owner. Envoys champion the needs of their own clients by restoring their file handles to working status and resuming their suspended operations, while the operations initiated by failed envoys are forgotten and their files implicitly closed.

If certain write operations were in progress when the failure occurred, it is possible that orphaned objects may result. The operations can still succeed, but objects that were created but not linked to may be lost to the system. Snapshots and the copy-on-write mechanism expose particular vulnerabilities with their leaf-to-root clone-and-update procedure, potentially losing chains of cloned directory objects if interrupted by an ill-timed failure. This does not result in data loss, but it may leave an occasional object that cannot be reached through the file tree. The potential for minor capacity loss is regrettable, but the likelihood and magnitude of the problem are both low and can be ignored.

\subsection{Special cases}

Throwing away damaged soft state and rebuilding it instead of trying to patch it makes recovery from a node failure simple and uniform across a range of failure conditions. An important step in the process depends on the ability of newly-ostracised envoys to rejoin the collective by starting at the root of the tree and pushing file handles back down to their appropriate locations. Two problems can inhibit this process: failure of the root node, or a change in the path from the root to the target node.

Every node that joins the Envoy system must know how to locate the root node. Whenever a client attempts to mount a file system image, it specifies it as the path from the root of the global namespace to the root of the image. Locating the root initially may be part of the startup process for an envoy, or it may integrate more closely with a higher-level service-cluster management tool. Other management services must exist to instantiate and monitor client VMs, and it is sensible to have Envoy coordinate directly with those services. Monitoring the root node and anointing a replacement when it fails could fall to the management tools as well, or envoys could instead be started with an ordered list of root nodes, the next taking over when the previous fails.

The rest of the recovery process need not be changed for the root node, as the existing procedure would suffice. It may prove worthwhile to treat it as an exception, however. In the prototype, all of the top-level administrative directories are managed by a single envoy, with the transition to individual images being the first point at which territory ownership changes are allowed. While this is just a simplification for the prototype, an implementation with no such restriction would probably follow that pattern quite often, as most clients would mount an image and then never interact with administrative directories again. The root node may end up with many more children than a typical node, and dissolving all territory boundaries would disrupt the whole cluster instead of localised regions of related clients. As an optimisation, the root node could log territory changes that it observes into a regular file with a well-known name (periodically checkpointing by dumping a complete list). Its successor would then start in the normal way, read the log file, and then contact each child to inform it of the change. This would also require that children of the root be aware of their special status so that they would not dissolve their branch of the tree upon detecting the root node failure.

Renaming a directory always throws file handles for its descendents temporarily out-of-sync. A recursive update procedure ensures that this does not last too long, but node failure could interrupt the propagation of the update, or the update could happen after a descendent fails but before other affected nodes have fully recovered; in either case the file handles that they use to reconnect would have incorrect pathnames. Renaming high-level directories is already quite rare, and having it coincide with a node failure is quite unlikely. It would be reasonable to simply report a stale file handle to the client when this happens, forcing it to locate its files again and re-open them. Alternatively, the messages used to propagate renames down the territory tree could be adapted to implement a two-phase commit protocol. This would also prevent other potential race conditions that might come up when renaming directories.

Besides envoy failure, storage node failure and network partitions can also disrupt a running system. Both problems are the province of the storage layer. The occasional failure of a storage node is expected and is one of the reasons for replication of all stored objects. A failure can be tolerated and repaired without disrupting the running system (other than possible performance degradation), though the details of recovery are part of the object storage system and omitted from this dissertation.

The network partition case is more serious, as it resembles the simultaneous failure of many nodes. The most important consideration is to prevent permanent data loss, which means preventing conflicting updates that cannot later be resolved. By relying on the storage layer, this can be easily resolved: envoys can only make binding changes in the storage layer when they can contact a majority of the replicas. If a small part of the network is isolated, it will soon fail until connectivity is restored. If the larger portion retains enough storage servers, it can continue on uninterrupted, but it may also happen that both parts of the network are disabled until the problem is resolved. Network partitions are a traditional bane of distributed systems, but they are less of a concern in cluster settings, because of redundancy in the network itself. Redundant network interfaces, routers, and switches make it unlikely that groups of machines will be isolated, so requiring a repair before resuming normal operation is reasonable. Using SCTP \cite{stewart} instead of TCP gives built-in multihoming support, so isolated network failures can be tolerated without the envoy service taking any explicit action.

\section{Summary}

The Envoy file system is a distributed storage system designed for service clusters. It assumes a cluster environment with well-maintained machines and sufficient redundancy to prevent correlated component failures.

Envoy runs a service on each node in a trusted administrative virtual machine, which exports file services to clients on the same node. A separate storage layer provides an object-level data abstraction, which the envoy layer uses to compile a file system. Control of the file tree is divided into \emph{territories}, or subtrees which may themselves be further subdivided. A territory is \emph{owned} by one envoy node, which maintains a persistent and in-memory cache for it and acts as server to all clients that access it. Client requests for remote territories are forwarded by the local envoy. Relationships between envoys are maintained only when they have neighbouring territories, or when one is handling client requests on the other's behalf.

File system images are subtrees within the global namespace that are treated as management units. Lightweight snapshot and fork operations use copy-on-write techniques to enhance performance and encourage sharing even between unrelated clients. After a snapshot, all objects become globally read-only and can be cached anywhere in the cluster without further coordination. Each writable object is owned by a single envoy that coordinates all access to it, and clients share a node-level cache, so consistency is guaranteed.

Control of an image is initially handed to the envoy of the first client that mounts it, but territories may be migrated, split, and re-merged in response to demand. A greedy algorithm monitors client usage and finds the most urgent transfer, or the one that will benefit the remote node the most while hurting the current owner the least. The level of urgency determines how quickly the transfer will happen, with low urgency migrations being delayed to promote stability and effective cache use, while more pressing moves are made quickly.

The fate of clients is tied to their local envoys, which maintain copies of all their runtime file system state. The failure of an envoy dissolves all territories below it in the hierarchy, forcing descendents in the tree to re-join the active system by walking from the global root down to the locations of files that are still active. Node failure only requires action from envoys that had some kind of working relationship with the failed node.
