\chapter{The \envoy Model}

This chapter examines the storage needs of service clusters and how they can be accommodated. Service clusters place specific demands on the storage system to efficiently support the deployment and management of untrusted services, but they also present helpful properties that can simplify the job. In addition to detailing these constraints, this chapter describes \envoy, a file system designed for this environment.

\section{Distribution}

VM migration \cite{clark} is essential for load balancing and uninterrupted service in the presence of hardware servicing.

To support migration, a file system cannot be tied to a single physical machine. Any given file system image must be as mobile as the service that relies on it.

Three basic architectures are available. A centralized server model is the simplest and satisfies the mobility requirement, but it doesn't scale well and suffers from a single point of failure. This model has been extended quite successfully using RAIDs and SANs on the back end to increase performance and robustness, and by caching on the client end to reduce load, but it is still limited. Ultimately, all decisions are moderated by a single host which must communicate directly with all clients, so at larger scale the network bandwidth becomes a problem as well.

At the other extreme, coordinations is pushed completely to the clients. This is essentially the centralized model turned upside down. Instead of many clients talking to a single server, a single client must communicate with many servers. Instead of one congestion point, every client becomes overwhelmed with bookkeeping. In practice, some structure can be introduced so that the system isn't a full $n$-way clique---the host for each object of storage may become the mediator for access to that object, for example---but making every participant a symmetric peer is mostly useful for privacy or other non-technical concerns.

A more practical approach is to emulate a centralized architecture as much as possible, since this provides the simplest model with the least administrative overhead, and carve up the problem enough to achieve the desired scaling properties. The two extremes offer the greatest conceptual purity, but the practical benefits are to be had somewhere between them. Most P2P services now introduce some kind of a hierarchy that designates some hosts as ``superpeers'' or ``supernodes'' that act as aggregation points for a manageable set of participants. These distinguished hosts only need to communicate directly with other similarly endowed hosts, potentially reducing the visible size of the network by orders of magnitude. The world is small enough and computers big enough that a few orders of magnitude is enough reduction to make many distributed problems tractable.

In service clusters, physical hosts are divided into roughly 10s of services, which may be transient, untrusted, and unreliable. This increases the number of participants requiring access to the storage system by the same factor and exposes difficult security problems. One of the principle benefits of isolating services in individual virtual machines is in reducing the impact of services that fail, either benignly or maliciously, and trusting the administration of the file system to the services negates this benefit.

The environment includes a trusted management domain on each server, however, which introduces a natural aggregation point and a way to sidestep many of those problems.

\section{Local impact}

\envoy is designed according to the principle of \textit{local impact}, meaning that the resources consumed directly or indirectly by a service should be as close to that service as possible. If not in the same VM, then on the same machine, or on another machine that has some specific reason to yield its resources to a remote service.

By extension, this principle leads to a topology that is shaped according to runtime conflicts. When there is no reason to suspect contention, machines will prefer to assume complete control over the storage in active use by their client services. If two machines must explicitly coordinate their access to storage, they are treading on overlapping or neighboring storage and implicitly declaring that a conflict is likely to occur.

Previous studies of file system traffic have repeatedly concluded that runtime contention is rare, so \envoy is designed to assume that exclusive access dominates and react to conflicts as they occur rather than optimizing for the occasions when access overlaps.

\section{Outline of the other stuff}
\subsection{Goals of Envoy}
\subsubsection{Things that a VM cluster calls for}
\begin{itemize}
\item virtual machine clusters---admin domain as aggregator and secure manager
\item mobile VMs
\item stock base images with customization---rapid deployment of services
\item commodity disks
\item snapshots and forks
\end{itemize}

\subsubsection{Desirable properties that the envoy model achieves}
\begin{itemize}
\item distribute only when there's a reason; favor centralization when practical
\item perfectly consistent persistent caching
\item local impact---heavy users bear most of the load, non-users none of it
\item serve from local machine cache when uncontended, NFS-like when shared: requests never require topology changes
\item in steady state, coordination based on actual contention, not potential contention
\item simple security model that maps well to familiar Unix semantics
\item private images act like local images, shared images scale gracefully
\end{itemize}

\section{Use and administration}

This section presents the administrative interface to \envoy, which is designed as a series of special file operations and conventions.

\subsection{High-level architecture overview}
Big diagram.
\subsection{Storage layer}
\subsection{Envoy layer}
\subsection{Lease migration}
\subsection{Forks and snapshots}
\subsection{Security}
\subsection{Recovery}
\subsection{Deleting snapshots}